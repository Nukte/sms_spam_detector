{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lQCQqD98930i",
        "ZTkcAFTA9_5e",
        "ndd9P8IWmv-Y",
        "wcSV1PLR-606",
        "j_1EuoAy-ifU",
        "YRaP_dwPSaSV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukte/Turkish_Sentence_Mood_Analysis/blob/main/SpamDetectorCaseStudy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Spam Detector | Case Study**"
      ],
      "metadata": {
        "id": "KLhxRlxbm8MV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Birinci Deneme - Naive Bayes*\n",
        "\n",
        "\n",
        "*   Naive Bayes (Kelime) Whatsapp gurubundan aldığım kodlar..\n",
        "*   Naive Bayes (Karakter) Whatsapp gurubundan aldığım kodlarda yaptığım iyleştirme.\n",
        "\n"
      ],
      "metadata": {
        "id": "NSKXrjM-mgZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ----- Naive Bayes (Kelime) // Whatsapp Grubundan aldığım kodlar.\n"
      ],
      "metadata": {
        "id": "M8TUhS2r4eL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "# ---------------------------------------------------------\n",
        "# A. VERİ HAZIRLIĞI (DATA PREPARATION)\n",
        "# ---------------------------------------------------------\n",
        "# 1. Veriyi Yükle\n",
        "# 'mail_data.csv' dosyasını okuyoruz.\n",
        "raw_mail_data = pd.read_csv('mail_data.csv')\n",
        "\n",
        "# 2. Eksik Verileri Doldur\n",
        "# Eğer boş hücre varsa onları boş string ile dolduruyoruz hata vermemesi için.\n",
        "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')\n",
        "\n",
        "# 3. Etiketleme (Label Encoding)\n",
        "# Makine kelimeden anlamaz, bu yüzden:\n",
        "# spam -> 1 (Tehlikeli)\n",
        "# ham  -> 0 (Güvenli) olarak işaretliyoruz.\n",
        "mail_data.loc[mail_data['Category'] == 'spam', 'Category'] = 1\n",
        "mail_data.loc[mail_data['Category'] == 'ham', 'Category'] = 0\n",
        "\n",
        "X = mail_data['Message']\n",
        "Y = mail_data['Category'].astype(int)\n",
        "# ---------------------------------------------------------\n",
        "# B. NETLEŞTİRME VE TWEAKING (STRATEJİK BÖLÜM)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 4. Veriyi Bölme (Stratified Split)\n",
        "# Veriyi %80 Eğitim (Train), %20 Test olarak ayırıyoruz.\n",
        "# ÖNEMLİ TWEAK: 'stratify=Y' komutu ile test setinde de eğitim setinde de\n",
        "# spam oranının eşit olmasını garantiliyoruz. Böylece model dengesiz öğrenmiyor.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3, stratify=Y)\n",
        "\n",
        "# 5. Özellik Çıkarımı (Feature Extraction & N-Grams)\n",
        "# Metinleri sayısal vektörlere dönüştürüyoruz.\n",
        "# TWEAKING DETAYI: Bu sayede model sadece \"kazan\" kelimesine değil, \"ödül kazan\" ikilisine de bakıyor.\n",
        "# Bu yöntem spam tespitini çok daha keskin (precise) hale getirir.\n",
        "feature_extraction = TfidfVectorizer(  #Kelime analizi\n",
        "    min_df=1,\n",
        "    #analyzer='word' şeklinde de tanımlanabilir.\n",
        "    stop_words='english',\n",
        "    lowercase=True, ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "# Eğitim verisine göre sözlüğümüzü oluşturuyoruz ve dönüştürüyoruz.\n",
        "X_train_features = feature_extraction.fit_transform(X_train)\n",
        "X_test_features = feature_extraction.transform(X_test)\n",
        "# ---------------------------------------------------------\n",
        "# C. MODELLEME (MODELING)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 6. Model Seçimi ve Eğitimi\n",
        "# Naive Bayes (MultinomialNB) metin sınıflandırmada en hızlı ve etkili yöntemlerden biridir.\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 7. Test ve Sonuç\n",
        "prediction_on_test_data = model.predict(X_test_features)\n",
        "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)\n",
        "\n",
        "cm = confusion_matrix(Y_test, prediction_on_test_data)\n",
        "\n",
        "print(f\" (Naive Bayes): {accuracy_on_test_data * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Karmaşıklık Matrisinden değerleri çıkarma\n",
        "tn = cm[0, 0] # True Negative: Gerçek Ham, Tahmin Ham\n",
        "fp = cm[0, 1] # False Positive: Gerçek Ham, Tahmin Spam\n",
        "fn = cm[1, 0] # False Negative: Gerçek Spam, Tahmin Ham\n",
        "tp = cm[1, 1] # True Positive: Gerçek Spam, Tahmin Spam\n",
        "\n",
        "gercek_spam = fn + tp\n",
        "gercek_ham = tn + fp\n",
        "toplam_test_mail = gercek_spam + gercek_ham\n",
        "\n",
        "print(\"\\n==================================================================\")\n",
        "print(\" NAİVE BAYES KELİME BAZLI ANALİZ SONUCU\")\n",
        "print(\"==================================================================\")\n",
        "\n",
        "# 1. SPAM Maillerin Durumu (Kaçırılanlar)\n",
        "print(f\"1. GERÇEK SPAM Mail Sayısı: {gercek_spam}\")\n",
        "print(f\"   - Tespit Edilen SPAM Maili (TP): {tp}\")\n",
        "print(f\"   - Kaçırılan SPAM Maili (FN):   {fn}\")\n",
        "\n",
        "# 2. HAM Maillerin Durumu (Yanlış İşaretlenenler)\n",
        "print(f\"\\n2. GERÇEK HAM Mail Sayısı: {gercek_ham}\")\n",
        "print(f\"   - Tespit Edilen HAM Maili (TN): {tn}\")\n",
        "print(f\"   - SPAM İşaretlenen HAM Maili (FP): {fp}\")\n",
        "\n",
        "print(\"\\n--- ÖZET METRİKLER ---\")\n",
        "print(f\"Toplam Test Edilen Mail Sayısı: {toplam_test_mail}\")\n",
        "print(f\"Modelin Genel Doğruluğu (Accuracy): {accuracy_on_test_data * 100:.2f}%\")\n",
        "print(\"==================================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0b5roiPmeCH",
        "outputId": "28c2981a-2b0f-4588-fed3-829040e09bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Naive Bayes): 95.96%\n",
            "Confusion Matrix:\n",
            "[[966   0]\n",
            " [ 45 104]]\n",
            "\n",
            "==================================================================\n",
            " NAİVE BAYES KELİME BAZLI ANALİZ SONUCU\n",
            "==================================================================\n",
            "1. GERÇEK SPAM Mail Sayısı: 149\n",
            "   - Tespit Edilen SPAM Maili (TP): 104\n",
            "   - Kaçırılan SPAM Maili (FN):   45\n",
            "\n",
            "2. GERÇEK HAM Mail Sayısı: 966\n",
            "   - Tespit Edilen HAM Maili (TN): 966\n",
            "   - SPAM İşaretlenen HAM Maili (FP): 0\n",
            "\n",
            "--- ÖZET METRİKLER ---\n",
            "Toplam Test Edilen Mail Sayısı: 1115\n",
            "Modelin Genel Doğruluğu (Accuracy): 95.96%\n",
            "==================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -----Naive Bayes (Karakter)"
      ],
      "metadata": {
        "id": "h9DU8Bdp3Lni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# A. VERİ HAZIRLIĞI (DATA PREPARATION)\n",
        "# ---------------------------------------------------------\n",
        "# 1. Veriyi Yükle\n",
        "# 'mail_data.csv' dosyasını okuyoruz.\n",
        "raw_mail_data = pd.read_csv('mail_data.csv')\n",
        "\n",
        "# 2. Eksik Verileri Doldur\n",
        "# Eğer boş hücre varsa onları boş string ile dolduruyoruz hata vermemesi için.\n",
        "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')\n",
        "\n",
        "# 3. Etiketleme (Label Encoding)\n",
        "# Makine kelimeden anlamaz, bu yüzden:\n",
        "# spam -> 1 (Tehlikeli)\n",
        "# ham  -> 0 (Güvenli) olarak işaretliyoruz.\n",
        "mail_data.loc[mail_data['Category'] == 'spam', 'Category'] = 1\n",
        "mail_data.loc[mail_data['Category'] == 'ham', 'Category'] = 0\n",
        "\n",
        "X = mail_data['Message']\n",
        "Y = mail_data['Category'].astype(int)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# B. NETLEŞTİRME VE TWEAKING (STRATEJİK BÖLÜM)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 4. Veriyi Bölme (Stratified Split)\n",
        "# Veriyi %80 Eğitim (Train), %20 Test olarak ayırıyoruz.\n",
        "# ÖNEMLİ TWEAK: 'stratify=Y' komutu ile test setinde de eğitim setinde de\n",
        "# spam oranının eşit olmasını garantiliyoruz. Böylece model dengesiz öğrenmiyor.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3, stratify=Y)\n",
        "\n",
        "# 5. Özellik Çıkarımı (Feature Extraction & N-Grams)\n",
        "# Metinleri sayısal vektörlere dönüştürüyoruz.\n",
        "\n",
        "# TWEAKING DETAYI: 'analyzer='char_wb'' ve 'ngram_range=(2, 2)' parametreleri eklendi.\n",
        "# Bu sayede model, \"kelime\" olarak görülemeyen yazım hatalarını (örn: 'fr33', 'w.i.n')\n",
        "# ve karakter bazlı gizleme tekniklerini yakalar.\n",
        "feature_extraction = TfidfVectorizer(\n",
        "    min_df=1,\n",
        "    analyzer='char_wb',\n",
        "    lowercase=True,\n",
        "    ngram_range=(2,2)  # ikili karakter kontrolü  (ab , cd )\n",
        ")\n",
        "# Eğitim verisine göre sözlüğümüzü oluşturuyoruz ve dönüştürüyoruz.\n",
        "X_train_features = feature_extraction.fit_transform(X_train)\n",
        "X_test_features = feature_extraction.transform(X_test)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# C. MODELLEME (MODELING)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 6. Model Seçimi ve Eğitimi\n",
        "# Naive Bayes (MultinomialNB) metin sınıflandırmada en hızlı ve etkili yöntemlerden biridir.\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 7. Test ve Sonuç\n",
        "prediction_on_test_data = model.predict(X_test_features)\n",
        "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)\n",
        "cm = confusion_matrix(Y_test, prediction_on_test_data)\n",
        "\n",
        "print(f\" (Naive Bayes): {accuracy_on_test_data * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Karmaşıklık Matrisinden değerleri çıkarma\n",
        "tn = cm[0, 0] # True Negative: Gerçek Ham, Tahmin Ham\n",
        "fp = cm[0, 1] # False Positive: Gerçek Ham, Tahmin Spam\n",
        "fn = cm[1, 0] # False Negative: Gerçek Spam, Tahmin Ham\n",
        "tp = cm[1, 1] # True Positive: Gerçek Spam, Tahmin Spam\n",
        "\n",
        "gercek_spam = fn + tp\n",
        "gercek_ham = tn + fp\n",
        "toplam_test_mail = gercek_spam + gercek_ham\n",
        "\n",
        "print(\"\\n==================================================================\")\n",
        "print(\" NAİVE BAYES KARAKTER BAZLI ANALİZ SONUCU\")\n",
        "print(\"==================================================================\")\n",
        "\n",
        "# 1. SPAM Maillerin Durumu (Kaçırılanlar)\n",
        "print(f\"1. GERÇEK SPAM Mail Sayısı: {gercek_spam}\")\n",
        "print(f\"   - Tespit Edilen SPAM Maili (TP): {tp}\")\n",
        "print(f\"   - Kaçırılan SPAM Maili (FN):   {fn}\")\n",
        "\n",
        "# 2. HAM Maillerin Durumu (Yanlış İşaretlenenler)\n",
        "print(f\"\\n2. GERÇEK HAM Mail Sayısı: {gercek_ham}\")\n",
        "print(f\"   - Tespit Edilen HAM Maili (TN): {tn}\")\n",
        "print(f\"   - SPAM İşaretlenen HAM Maili (FP): {fp}\")\n",
        "\n",
        "print(\"\\n--- ÖZET METRİKLER ---\")\n",
        "print(f\"Toplam Test Edilen Mail Sayısı: {toplam_test_mail}\")\n",
        "print(f\"Modelin Genel Doğruluğu (Accuracy): {accuracy_on_test_data * 100:.2f}%\")\n",
        "print(\"==================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dw3Iuie0vQk",
        "outputId": "d4c23295-f20d-41ba-f12c-4ca3cf0e32bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Naive Bayes): 97.67%\n",
            "Confusion Matrix:\n",
            "[[965   1]\n",
            " [ 25 124]]\n",
            "\n",
            "==================================================================\n",
            " NAİVE BAYES KARAKTER BAZLI ANALİZ SONUCU\n",
            "==================================================================\n",
            "1. GERÇEK SPAM Mail Sayısı: 149\n",
            "   - Tespit Edilen SPAM Maili (TP): 124\n",
            "   - Kaçırılan SPAM Maili (FN):   25\n",
            "\n",
            "2. GERÇEK HAM Mail Sayısı: 966\n",
            "   - Tespit Edilen HAM Maili (TN): 965\n",
            "   - SPAM İşaretlenen HAM Maili (FP): 1\n",
            "\n",
            "--- ÖZET METRİKLER ---\n",
            "Toplam Test Edilen Mail Sayısı: 1115\n",
            "Modelin Genel Doğruluğu (Accuracy): 97.67%\n",
            "==================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *İkinci Deneme - Logistic Regression*\n",
        "\n",
        "\n",
        "*   LR (Kelime)\n",
        "*   LR (Karakter)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2pL1CM7Mm3lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression (Kelime)"
      ],
      "metadata": {
        "id": "lQCQqD98930i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# A. VERİ YÜKLEME VE ÖN İŞLEME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Veriyi Yükleme\n",
        "try:\n",
        "    df = pd.read_csv('mail_data.csv')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
        "\n",
        "df.columns = ['Category', 'Message']\n",
        "df = df[['Category', 'Message']]\n",
        "df = df.where((pd.notnull(df)), '')\n",
        "\n",
        "# 2. Etiketleme (Label Encoding): bilgisayar anlasın diye ham -> 0, spam -> 1\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message']\n",
        "Y = df['Category']\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# B. VERİYİ BÖLME VE ÖZELLİK ÇIKARIMI\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3. Veriyi Bölme (Stratified Split)\n",
        "# Veriyi %80 Eğitim, %20 Test olarak ayırır. stratify=Y, spam oranını korur.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "# 4. Özellik Çıkarımı (TF-IDF N-Gram)\n",
        "# Metni sayısal vektörlere dönüştürür. ngram_range=(1, 2) ile kelime gruplarını kullanırız.\n",
        "vectorizer = TfidfVectorizer(\n",
        "    min_df=1,\n",
        "    stop_words='english',\n",
        "    lowercase=True,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "X_train_features = vectorizer.fit_transform(X_train)\n",
        "X_test_features = vectorizer.transform(X_test)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# C. MODELLEME VE DEĞERLENDİRME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 5. Model Seçimi ve Eğitimi\n",
        "# Lojistik Regresyon, Naive Bayes'ten daha iyi bir sınıflandırma sınırı çiziyor\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', C=100, random_state=42)\n",
        "#liblinear en iyi sonuç veren solver\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 6. Test ve Değerlendirme\n",
        "y_pred = model.predict(X_test_features)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print(f\" (Lojistik Regresyon): {accuracy * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Karmaşıklık Matrisinden değerleri çıkarma\n",
        "tn = cm[0, 0] # True Negative: Gerçek Ham, Tahmin Ham\n",
        "fp = cm[0, 1] # False Positive: Gerçek Ham, Tahmin Spam\n",
        "fn = cm[1, 0] # False Negative: Gerçek Spam, Tahmin Ham\n",
        "tp = cm[1, 1] # True Positive: Gerçek Spam, Tahmin Spam\n",
        "\n",
        "gercek_spam = fn + tp\n",
        "gercek_ham = tn + fp\n",
        "toplam_test_mail = gercek_spam + gercek_ham\n",
        "\n",
        "print(\"\\n==================================================================\")\n",
        "print(\" LOJİSTİK REGRESYON KELİME BAZLI ANALİZ SONUCU\")\n",
        "print(\"==================================================================\")\n",
        "\n",
        "# 1. SPAM Maillerin Durumu (Kaçırılanlar)\n",
        "print(f\"1. GERÇEK SPAM Mail Sayısı: {gercek_spam}\")\n",
        "print(f\"   - Tespit Edilen SPAM Maili (TP): {tp}\")\n",
        "print(f\"   - Kaçırılan SPAM Maili (FN):   {fn}\")\n",
        "\n",
        "# 2. HAM Maillerin Durumu (Yanlış İşaretlenenler)\n",
        "print(f\"\\n2. GERÇEK HAM Mail Sayısı: {gercek_ham}\")\n",
        "print(f\"   - Tespit Edilen HAM Maili (TN): {tn}\")\n",
        "print(f\"   - SPAM İşaretlenen HAM Maili (FP): {fp}\")\n",
        "\n",
        "print(\"\\n--- ÖZET METRİKLER ---\")\n",
        "print(f\"Toplam Test Edilen Mail Sayısı: {toplam_test_mail}\")\n",
        "print(f\"Modelin Genel Doğruluğu (Accuracy): {accuracy * 100:.2f}%\")\n",
        "print(\"==================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWKKK_xhm5h0",
        "outputId": "c7a8e58d-4904-44bb-d284-2ee1f211e057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Lojistik Regresyon): 98.30%\n",
            "Confusion Matrix:\n",
            "[[962   4]\n",
            " [ 15 134]]\n",
            "\n",
            "==================================================================\n",
            " LOJİSTİK REGRESYON KELİME BAZLI ANALİZ SONUCU\n",
            "==================================================================\n",
            "1. GERÇEK SPAM Mail Sayısı: 149\n",
            "   - Tespit Edilen SPAM Maili (TP): 134\n",
            "   - Kaçırılan SPAM Maili (FN):   15\n",
            "\n",
            "2. GERÇEK HAM Mail Sayısı: 966\n",
            "   - Tespit Edilen HAM Maili (TN): 962\n",
            "   - SPAM İşaretlenen HAM Maili (FP): 4\n",
            "\n",
            "--- ÖZET METRİKLER ---\n",
            "Toplam Test Edilen Mail Sayısı: 1115\n",
            "Modelin Genel Doğruluğu (Accuracy): 98.30%\n",
            "==================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression (Karakter)"
      ],
      "metadata": {
        "id": "ZTkcAFTA9_5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# A. VERİ YÜKLEME VE ÖN İŞLEME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Veriyi Yükleme\n",
        "try:\n",
        "    df = pd.read_csv('mail_data.csv')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
        "\n",
        "df.columns = ['Category', 'Message']\n",
        "df = df[['Category', 'Message']]\n",
        "df = df.where((pd.notnull(df)), '')\n",
        "\n",
        "# 2. Etiketleme (Label Encoding): ham -> 0, spam -> 1\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message']\n",
        "Y = df['Category']\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# B. VERİYİ BÖLME VE ÖZELLİK ÇIKARIMI\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3. Veriyi Bölme (Stratified Split)\n",
        "# Veriyi %80 Eğitim, %20 Test olarak ayırır. stratify=Y, spam oranını korur.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "# 4. Özellik Çıkarımı (TF-IDF N-Gram)\n",
        "# Metni sayısal vektörlere dönüştürür. ngram_range=(1, 2) ile kelime gruplarını kullanırız.\n",
        "vectorizer = TfidfVectorizer(\n",
        "    min_df=1,\n",
        "    analyzer='char_wb',\n",
        "    lowercase=True,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "X_train_features = vectorizer.fit_transform(X_train)\n",
        "X_test_features = vectorizer.transform(X_test)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# C. MODELLEME VE DEĞERLENDİRME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 5. Model Seçimi ve Eğitimi\n",
        "# Lojistik Regresyon, Naive Bayes'ten daha iyi bir sınıflandırma sınırı çizerek FN'i düşürmemizi sağlar.\n",
        "model = LogisticRegression(solver='liblinear', C=100, random_state=42)\n",
        "#liblinear ile FP 0 -  FN 13 sonucunu alırken saga ile FP 3 - FN 9 sonucunu alıyorum.\n",
        "#saga spam mail yakalama konusunda daha iyi fakat normal maillerimizi kaybetmek istemiyorum.\n",
        "#o yüzden liblinear benim için daha iyi bir seçenek.\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 6. Test ve Değerlendirme\n",
        "y_pred = model.predict(X_test_features)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print(f\" (Lojistik Regresyon): {accuracy * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Karmaşıklık Matrisinden değerleri çıkarma\n",
        "tn = cm[0, 0] # True Negative: Gerçek Ham, Tahmin Ham\n",
        "fp = cm[0, 1] # False Positive: Gerçek Ham, Tahmin Spam\n",
        "fn = cm[1, 0] # False Negative: Gerçek Spam, Tahmin Ham\n",
        "tp = cm[1, 1] # True Positive: Gerçek Spam, Tahmin Spam\n",
        "\n",
        "gercek_spam = fn + tp\n",
        "gercek_ham = tn + fp\n",
        "toplam_test_mail = gercek_spam + gercek_ham\n",
        "\n",
        "print(\"\\n==================================================================\")\n",
        "print(\" LOJİSTİK REGRESYON KARAKTER BAZLI ANALİZ SONUCU\")\n",
        "print(\"==================================================================\")\n",
        "\n",
        "# 1. SPAM Maillerin Durumu (Kaçırılanlar)\n",
        "print(f\"1. GERÇEK SPAM Mail Sayısı: {gercek_spam}\")\n",
        "print(f\"   - Tespit Edilen SPAM Maili (TP): {tp}\")\n",
        "print(f\"   - Kaçırılan SPAM Maili (FN):   {fn}\")\n",
        "\n",
        "# 2. HAM Maillerin Durumu (Yanlış İşaretlenenler)\n",
        "print(f\"\\n2. GERÇEK HAM Mail Sayısı: {gercek_ham}\")\n",
        "print(f\"   - Tespit Edilen HAM Maili (TN): {tn}\")\n",
        "print(f\"   - SPAM İşaretlenen HAM Maili (FP): {fp}\")\n",
        "\n",
        "print(\"\\n--- ÖZET METRİKLER ---\")\n",
        "print(f\"Toplam Test Edilen Mail Sayısı: {toplam_test_mail}\")\n",
        "print(f\"Modelin Genel Doğruluğu (Accuracy): {accuracy * 100:.2f}%\")\n",
        "print(\"==================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOzj-Psk-Dnx",
        "outputId": "198b2252-bb32-48fc-9121-82ff665c3371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Lojistik Regresyon): 98.83%\n",
            "Confusion Matrix:\n",
            "[[966   0]\n",
            " [ 13 136]]\n",
            "\n",
            "==================================================================\n",
            " LOJİSTİK REGRESYON KARAKTER BAZLI ANALİZ SONUCU\n",
            "==================================================================\n",
            "1. GERÇEK SPAM Mail Sayısı: 149\n",
            "   - Tespit Edilen SPAM Maili (TP): 136\n",
            "   - Kaçırılan SPAM Maili (FN):   13\n",
            "\n",
            "2. GERÇEK HAM Mail Sayısı: 966\n",
            "   - Tespit Edilen HAM Maili (TN): 966\n",
            "   - SPAM İşaretlenen HAM Maili (FP): 0\n",
            "\n",
            "--- ÖZET METRİKLER ---\n",
            "Toplam Test Edilen Mail Sayısı: 1115\n",
            "Modelin Genel Doğruluğu (Accuracy): 98.83%\n",
            "==================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Üçüncü Deneme - LinearSVC*\n",
        "\n",
        "\n",
        "*   LSVC (Kelime)\n",
        "*   LSVC (Karakter)\n",
        "\n"
      ],
      "metadata": {
        "id": "ndd9P8IWmv-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSVC (Kelime)"
      ],
      "metadata": {
        "id": "wcSV1PLR-606"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC # En iyi sonuç veren model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# A. VERİ YÜKLEME VE ÖN İŞLEME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Veriyi Yükleme\n",
        "try:\n",
        "    df = pd.read_csv('mail_data.csv')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
        "\n",
        "df.columns = ['Category', 'Message']\n",
        "df = df[['Category', 'Message']]\n",
        "df = df.where((pd.notnull(df)), '')\n",
        "\n",
        "# 2. Etiketleme: ham -> 0, spam -> 1\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message']\n",
        "Y = df['Category']\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# B. VERİYİ BÖLME VE ÖZELLİK ÇIKARIMI\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3. Veriyi Bölme (Stratified Split)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "# 4. Özellik Çıkarımı (Karakter N-Gramları)\n",
        "# analyzer='char_wb' ile Karakter N-Gramları kullanılır.\n",
        "vectorizer_char = TfidfVectorizer(\n",
        "    min_df=1,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "# Vektörleyiciyi eğit ve veriyi dönüştür\n",
        "X_train_features = vectorizer_char.fit_transform(X_train)\n",
        "X_test_features = vectorizer_char.transform(X_test)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# C. MODELLEME VE DEĞERLENDİRME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 5. Modeli Eğitme (Linear SVC ile C=1.0)\n",
        "# yapay zeka deneme yanılma sonunca C=1.0 değeri en iyi dengeyi sağlamıştır.\n",
        "model = LinearSVC(random_state=42, C=1.0)\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 6. Test ve Değerlendirme\n",
        "y_pred = model.predict(X_test_features)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print(f\"Linear SVC: {accuracy * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_6ogPy0_BWv",
        "outputId": "351221da-d210-482b-ea61-c302faf7e2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVC: 98.30%\n",
            "Confusion Matrix:\n",
            "[[963   3]\n",
            " [ 16 133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSVC (Karakter)"
      ],
      "metadata": {
        "id": "j_1EuoAy-ifU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkalDzxVlmnh",
        "outputId": "4ab97ad7-eb0e-449b-f01c-baa6786d45b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NİHAİ MODEL BAŞARISI (Linear SVC + Karakter N-Gram): 99.01%\n",
            "Confusion Matrix:\n",
            "[[966   0]\n",
            " [ 11 138]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC # En iyi sonuç veren model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# A. VERİ YÜKLEME VE ÖN İŞLEME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Veriyi Yükleme\n",
        "try:\n",
        "    df = pd.read_csv('mail_data.csv')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
        "\n",
        "df.columns = ['Category', 'Message']\n",
        "df = df[['Category', 'Message']]\n",
        "df = df.where((pd.notnull(df)), '')\n",
        "\n",
        "# 2. Etiketleme: ham -> 0, spam -> 1\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message']\n",
        "Y = df['Category']\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# B. VERİYİ BÖLME VE ÖZELLİK ÇIKARIMI\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3. Veriyi Bölme (Stratified Split)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "# 4. Özellik Çıkarımı (Karakter N-Gramları)\n",
        "# analyzer='char_wb' ile Karakter N-Gramları kullanılır.\n",
        "vectorizer_char = TfidfVectorizer(\n",
        "    analyzer='char_wb',\n",
        "    ngram_range=(2, 4), # 2'li, 3'lü ve 4'lü karakter gruplarına bakar\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "# Vektörleyiciyi eğit ve veriyi dönüştür\n",
        "X_train_features = vectorizer_char.fit_transform(X_train)\n",
        "X_test_features = vectorizer_char.transform(X_test)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# C. MODELLEME VE DEĞERLENDİRME\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 5. Modeli Eğitme (Linear SVC ile C=1.0)\n",
        "# C=1.0 değeri en iyi dengeyi sağlamıştır.\n",
        "model = LinearSVC(random_state=42, C=1.0)\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# 6. Test ve Değerlendirme\n",
        "y_pred = model.predict(X_test_features)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print(f\"NİHAİ MODEL BAŞARISI (Linear SVC + Karakter N-Gram): {accuracy * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ekstra Test Kısmı (LinearSVC - Karakter Tabanlı Model)"
      ],
      "metadata": {
        "id": "YRaP_dwPSaSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# A. MODEL EĞİTİMİ (mail_data.csv KULLANILARAK)\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"--- 1. Model Eğitiliyor (mail_data.csv) ---\")\n",
        "\n",
        "# 1. Eğitim Verisini Yükleme\n",
        "try:\n",
        "    df = pd.read_csv('mail_data.csv')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
        "\n",
        "# Sütunları düzenleme\n",
        "df.columns = ['Category', 'Message']\n",
        "df = df.where((pd.notnull(df)), '')\n",
        "\n",
        "# Etiketleme: ham -> 0, spam -> 1\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message']\n",
        "Y = df['Category']\n",
        "\n",
        "# Veriyi Bölme\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
        ")\n",
        "\n",
        "# Özellik Çıkarımı (Eğitim verisi üzerinde 'fit' edilir)\n",
        "vectorizer_char = TfidfVectorizer(\n",
        "    analyzer='char_wb',\n",
        "    ngram_range=(2, 4),\n",
        "    lowercase=True\n",
        ")\n",
        "X_train_features = vectorizer_char.fit_transform(X_train)\n",
        "X_test_features = vectorizer_char.transform(X_test)\n",
        "\n",
        "# Modeli Eğitme\n",
        "model = LinearSVC(random_state=42, C=1.0)\n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# Eğitim Seti Üzerindeki Başarı (İç Test)\n",
        "train_acc = accuracy_score(Y_test, model.predict(X_test_features))\n",
        "print(f\"Modelin İç Test Başarısı (Validation): %{train_acc * 100:.2f}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# D. Ekstra test\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Dataset'te olmayan, tamamen uydurma cümleler\n",
        "my_custom_tests = [\n",
        "    # Zorlayıcı HAM -- bunları düzgün işaretleyebiliyor.\n",
        "    \"Hey can you send me the free ticket code you promised?\",\n",
        "    \"I won the chess tournament! It feels great.\",\n",
        "\n",
        "    # SPAM | yakalayamıyor -- eğitim setinde çok fazla böyle veri olmadığı için.\n",
        "    \"Urgent bank update. Click link to verify.\",\n",
        "    #kesin yakalıyor -- eğitim setinde bolca bunlardan var.\n",
        "    \"You have a package waiting. Pay shipping 2$ here.\"\n",
        "    \"WINNER! Claim your free prize now!\",\n",
        "    \"URGENT! Please call 09061213237 immediately.\",\n",
        "    \"Free entry to win 1000 cash txt CASH to 88888\"\n",
        "\n",
        "]\n",
        "\n",
        "# Tahmin\n",
        "features = vectorizer_char.transform(my_custom_tests)\n",
        "preds = model.predict(features)\n",
        "\n",
        "for text, label in zip(my_custom_tests, preds):\n",
        "    label_name = \"SPAM\" if label == 1 else \"HAM\"\n",
        "    print(f\"Mesaj: {text}\\nTahmin: {label_name}\\n---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcr35mEKSrOh",
        "outputId": "bec9830e-80e6-48a0-cfff-a54d9d4a4d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Model Eğitiliyor (mail_data.csv) ---\n",
            "Modelin İç Test Başarısı (Validation): %99.01\n",
            "\n",
            "==================================================\n",
            "Mesaj: Hey can you send me the free ticket code you promised?\n",
            "Tahmin: HAM\n",
            "---\n",
            "Mesaj: I won the chess tournament! It feels great.\n",
            "Tahmin: HAM\n",
            "---\n",
            "Mesaj: Urgent bank update. Click link to verify.\n",
            "Tahmin: HAM\n",
            "---\n",
            "Mesaj: You have a package waiting. Pay shipping 2$ here.WINNER! Claim your free prize now!\n",
            "Tahmin: SPAM\n",
            "---\n",
            "Mesaj: URGENT! Please call 09061213237 immediately.\n",
            "Tahmin: SPAM\n",
            "---\n",
            "Mesaj: Free entry to win 1000 cash txt CASH to 88888\n",
            "Tahmin: SPAM\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## grid search ile daha iyi bir sonuç elde edilebilir. Belki??"
      ],
      "metadata": {
        "id": "IZ3MNwrfU1eT"
      }
    }
  ]
}